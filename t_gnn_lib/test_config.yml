
data:
  seq_len_obs: 8
  seq_len_pred: 12
  path: dataset/A/A_B

model:
  input_size: 2
  feat_size: 64
  output_size: 5
  num_gcn: 3
  num_tcn: 3
  kernel_size: 3

training: 
  batch_size: 128
  num_epochs: 200
  lambda: 1         # hyperparmeter to balance loss terms
  lr: 0.001
  change_lr: 100    # Change learning rate after 100 epochs


model_path: experiments/training/69/checkpoints/epoch_200.pth